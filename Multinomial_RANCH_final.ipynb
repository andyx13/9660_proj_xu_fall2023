{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b3d95a5",
   "metadata": {},
   "source": [
    "# Multinomial RANCH Project Notebook\n",
    "\n",
    "#### Author: Guanpeng (Andy) Xu\n",
    "#### 9.660 Final Project, Fall 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4300ca95",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b156c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import gammaln as loggamma, digamma\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf1561",
   "metadata": {},
   "source": [
    "## Exemplars and Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829d9219",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplars =  np.array([[0,0,0], [0,0,1], [0,1,2], [1,2,3]]).astype(float) #feature values 0,1,2,3,4\n",
    "default_exemplars = np.array([np.array([0,0,1]).astype(float) for i in range(6)]).astype(float)\n",
    "\n",
    "deviant_exemplar = np.array([4,0,0]).astype(float)\n",
    "\n",
    "full_alphas_1 = np.array([[4, 1, 1, 1, 1],\n",
    "       [4, 1, 1, 1, 1],\n",
    "       [4, 1, 1, 1, 1]]).astype(float)\n",
    "full_alphas_2 = np.array([[3.6, 3.6, 3.6, 3.6, 3.6],\n",
    "       [3.6, 3.6, 3.6, 3.6, 3.6],\n",
    "       [3.6, 3.6, 3.6, 3.6, 3.6]]).astype(float) - 2.0\n",
    "\n",
    "full_alphas_3 = np.array([[0.04, 1.99, 1.99, 1.99, 1.99],\n",
    "       [0.04, 1.99, 1.99, 1.99, 1.99],\n",
    "       [0.04, 1.99, 1.99, 1.99, 1.99]]).astype(float)\n",
    "\n",
    "full_alphas_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dbc961",
   "metadata": {},
   "source": [
    "## RANCH implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e728827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_ = 0.065\n",
    "epsilons = [0.001, 0.01, 0.1, 0.2, 0.5, 0.7]\n",
    "epsilon_hat = 0.065\n",
    "EIG_env_ = 0.01\n",
    "numft, numval = full_alphas_1.shape\n",
    "\n",
    "\n",
    "def perturb(exemplar, epsilon = epsilon_hat):\n",
    "    rand_arr = np.random.rand(numft)\n",
    "    out = []\n",
    "    for ind in range(numft):\n",
    "        if rand_arr[ind] >= epsilon:\n",
    "            out.append(exemplar[ind])\n",
    "        else:\n",
    "            permute = 1 + int(4* rand_arr[ind]/epsilon) \n",
    "            out.append( (exemplar[ind] + permute)%5) \n",
    "        pass\n",
    "    return np.array(out)\n",
    "\n",
    "def compute_posterior_change(zs, epsilon):\n",
    "    \n",
    "    if len(zs) == 0:\n",
    "        return 1.0 * (np.ones((numval, ))/numval).astype(float)\n",
    "\n",
    "    \n",
    "    assert epsilon > 0\n",
    "    assert epsilon < 1\n",
    "    ci = np.ones((len(zs), numval)).astype(float) * np.log((epsilon/(numval - 1)))\n",
    "    \n",
    "    #each row is a z, each column is a feature value for y.\n",
    "    ci[[i for i in range(len(zs))], [int(x+ 0.001) for x in zs]] = np.log(1 - epsilon)\n",
    "    ci_out = np.sum(ci, axis = 0)\n",
    "    \n",
    "    assert ci_out.shape[0] == numval\n",
    "    return np.exp(ci_out)/np.sum(np.exp(ci_out))\n",
    "\n",
    "\n",
    "def EIG(alpha_priors, zs, epsilon = epsilon_):\n",
    "    \n",
    "    M = (1 - (numval * epsilon/(numval-1))) * np.eye(numval) + (epsilon/(numval - 1)) * np.ones((numval, numval))\n",
    "    \n",
    "    pi = compute_posterior_change(zs, epsilon)\n",
    "    \n",
    "    di = np.matmul(M, pi)\n",
    "    \n",
    "    probs = (di+alpha_priors)\n",
    "    probs = probs/np.sum(probs)\n",
    "    \n",
    "    EIG_ = 0\n",
    "    \n",
    "    for val in range(numval):\n",
    "        post_change = compute_posterior_change(zs + [val], epsilon)\n",
    "        EIG_ += KL(alpha_priors + post_change, alpha_priors + pi) * probs[val]\n",
    "\n",
    "    return EIG_\n",
    "\n",
    "\n",
    "def KL(alphas_1, alphas_2):\n",
    "    \n",
    "    loggamma1 = loggamma(np.sum(alphas_1))\n",
    "    loggamma2 = loggamma(np.sum(alphas_2))\n",
    "    loggamma3 = np.sum(loggamma(alphas_1))\n",
    "    loggamma4 = np.sum(loggamma(alphas_2))\n",
    "    diffs = alphas_1 - alphas_2\n",
    "    digamma_diffs = digamma(alphas_1) - digamma(np.sum(alphas_1))\n",
    "    \n",
    "    return (loggamma1 - loggamma2) + (loggamma4 - loggamma3) + np.dot(diffs, digamma_diffs)\n",
    "\n",
    "\n",
    "def ranch_sample(alpha_priors = full_alphas_1, exemplar_sequence = default_exemplars[:1], epsilon = epsilon_hat, EIG_env = EIG_env_):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return a sequence of looking times for each exemplar in the sequence, given a set of input priors and epsilon.\n",
    "    \"\"\"\n",
    "    \n",
    "    priors_modify = alpha_priors.copy()[:,:].astype(float)\n",
    "    out_array = []\n",
    "    \n",
    "    observations_so_far = []\n",
    "    \n",
    "    for exemplar in exemplar_sequence:\n",
    "        \n",
    "        r = 0 \n",
    "        \n",
    "        observations_so_far.append([])\n",
    "        sample = True\n",
    "        \n",
    "        while (sample and r < 5000): \n",
    "            z = perturb(exemplar, epsilon)\n",
    "            \n",
    "            EIG_next = 0\n",
    "            \n",
    "            for ft in range(numft):\n",
    "                zs_ft = [z[ft] for z in observations_so_far[-1]]\n",
    "                alphas_ft = priors_modify[ft,:].copy()\n",
    "                EIG_next += EIG(alphas_ft, zs_ft, epsilon)\n",
    "                \n",
    "            if (EIG_env + EIG_next) * np.random.rand() > EIG_next:\n",
    "                sample = False\n",
    "            r += 1\n",
    "            if r == 2500:\n",
    "                print('2500 iters done. EIG: ', EIG_next)\n",
    "                \n",
    "            if r == 5000:\n",
    "                print('Fail ', EIG_next)\n",
    "                \n",
    "            observations_so_far[-1].append(z)\n",
    "            \n",
    "        out_array.append(r)\n",
    "        for ft in range(numft):\n",
    "            zs_ft = [z[ft] for z in observations_so_far[-1]]\n",
    "            priors_modify[ft] += compute_posterior_change(zs_ft, epsilon)\n",
    "    \n",
    "    return np.array(out_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc0966e",
   "metadata": {},
   "source": [
    "## Multinomial RANCH Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea02552",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278cb12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict_e = {}\n",
    "seq_dict_EIG = {}\n",
    "seq_dict_alphas = {}\n",
    "\n",
    "for epsilon__ in epsilons: #Vary the modeled noise epsilon\n",
    "    print('EPS: ', epsilon__)\n",
    "    for l in trange(num_runs): #10000\n",
    "        seq_dict_e[epsilon__] = seq_dict_e.get(epsilon__, 0) +  (1.0/num_runs)* ranch_sample(epsilon = epsilon__)\n",
    "    \n",
    "print('')\n",
    "print('') \n",
    "for EIG_env__ in [0.001, 0.01, 0.1]: #Vary the modeled EIG\n",
    "    print('EIG_env: ', EIG_env__)\n",
    "    for l in trange(num_runs): #10000\n",
    "        seq_dict_EIG[EIG_env__] =seq_dict_EIG.get(EIG_env__, 0) + (1.0/num_runs) * ranch_sample(EIG_env = EIG_env__)\n",
    "print('')\n",
    "print('')  \n",
    "for i, alpha_arr in enumerate([full_alphas_1, full_alphas_2, full_alphas_3]):\n",
    "    print('ALPHA_ARR: ', alpha_arr[0])\n",
    "    for l in trange(num_runs):\n",
    "        seq_dict_alphas[i] = seq_dict_alphas.get(i, 0) + (1.0/num_runs) * ranch_sample(alpha_priors = alpha_arr.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888c8eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2965e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict_EIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f04ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_dict_alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8baef5",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict(dict_):\n",
    "    names = []\n",
    "    values = []\n",
    "    \n",
    "    for key in dict_:\n",
    "        names.append(str(key))\n",
    "        values.append(dict_[key][0])\n",
    "        \n",
    "    return names,values\n",
    "\n",
    "plt.bar(plot_dict(seq_dict_e)[0], plot_dict(seq_dict_e)[1])\n",
    "plt.xlabel('Modeled Noise $(\\epsilon)$' , fontsize = 13)\n",
    "plt.ylabel('Mean Iterations sampled', fontsize = 13)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(plot_dict(seq_dict_EIG)[0], plot_dict(seq_dict_EIG)[1])\n",
    "plt.xlabel('Modeled EIG(env)', fontsize = 13)\n",
    "plt.ylabel('Mean Iterations sampled', fontsize = 13)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(['Control-Biased Prior', 'Neutral Prior', 'Deviant-Biased Prior'], plot_dict(seq_dict_alphas)[1] )\n",
    "\n",
    "plt.ylim(3, 4)\n",
    "\n",
    "plt.ylabel('Mean Iterations sampled', fontsize = 13)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b7de39",
   "metadata": {},
   "source": [
    "## Complexity/Habituation Analysis\n",
    "\n",
    "### NOTE:\n",
    "The below code does not replicate well unless we use ~100000 samples per run (std of each exemplar ~1, and we want to distiguish below the 0.01 level). This takes about 30 minutes per run. Therefore, we run 10000 samples below in the notebook and accept some variance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca35080",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f661928",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea47f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compl = {} \n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    arr = np.array([exemplars[i].copy() for t in range(6) ]) \n",
    "    compl[str(arr[0] + 1)] = []\n",
    "    print(arr[0] + 1)\n",
    "\n",
    "    for l in trange(num_runs): \n",
    "        compl[str(arr[0] + 1)] = compl.get(str(arr[0] + 1)) + [ranch_sample(exemplar_sequence = arr)]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59508fb4",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = 'ov^s'\n",
    "\n",
    "for i, key in enumerate(compl):   \n",
    "    plt.plot([1,2,3,4,5,6], [np.mean([x[i] for x in compl[key]])  for i in range(6)], marker = markers[i], label = key)\n",
    "means = []\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    means.append(0)\n",
    "    for key in compl:\n",
    "        means[-1] += 0.25 * np.mean([x[i] for x in compl[key]])\n",
    "\n",
    "                                     \n",
    "plt.plot([1,2,3,4,5,6], means, label = 'Mean', color = 'black', linewidth = 2)\n",
    "plt.legend()  \n",
    "plt.xlabel('Repetition', fontsize = 13)\n",
    "plt.ylabel('Looking Iterations', fontsize = 13)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "                                     \n",
    "                                     \n",
    "                                     \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93691f7b",
   "metadata": {},
   "source": [
    "## Statistical Significance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm \n",
    "\n",
    "def z_score_p_val(lesser_arr, greater_arr): #perform a one-side two-sample z-score test\n",
    "    \n",
    "    n_1 = np.array(lesser_arr).shape[0]\n",
    "    n_2 = np.array(greater_arr).shape[0]\n",
    "    var1 = np.var(lesser_arr)\n",
    "    var2 = np.var(greater_arr)\n",
    "    z = (np.mean(greater_arr) - np.mean(lesser_arr))/np.sqrt(var1/(n_1)  + var2/(n_2 ))\n",
    "    p = 1 - norm.cdf(z)\n",
    "    \n",
    "    return z, p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac27b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_simple = compl['[1. 1. 1.]']\n",
    "arr_complex = compl['[2. 3. 4.]']\n",
    "z_value, p_value = z_score_p_val([np.sum(x) for x in arr_simple], [np.sum(x) for x in arr_complex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66980835",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Z-score: ', z_value)\n",
    "print('p-value: ', p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2970e2d7",
   "metadata": {},
   "source": [
    "## Dishabituation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6683b8d",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164944f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_runs = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dishab3 = {}\n",
    "dishab3['Control'] = []\n",
    "dishab3['Deviant #2'] = []\n",
    "dishab3['Deviant #4'] = []\n",
    "dishab3['Deviant #6'] = []\n",
    "\n",
    "arr = ([exemplars[1].copy() for t in range(6) ])\n",
    "print(arr)\n",
    "\n",
    "for l in trange(num_runs):\n",
    "    dishab3['Control'].append(ranch_sample(alpha_priors = full_alphas_1, exemplar_sequence = arr))\n",
    "\n",
    "arr = ([exemplars[1].copy() for t in range(1) ] + [deviant_exemplar.copy() for t in range(1) ] + [exemplars[1].copy() for t in range(4) ] )\n",
    "print(arr)\n",
    "\n",
    "for l in trange(num_runs):\n",
    "    dishab3['Deviant #2'] .append( ranch_sample(alpha_priors = full_alphas_1,exemplar_sequence = arr))\n",
    "\n",
    "\n",
    "arr = ([exemplars[1].copy() for t in range(3) ] + [deviant_exemplar.copy() for t in range(1) ] + [exemplars[1].copy() for t in range(2) ] )\n",
    "print(arr)\n",
    "\n",
    "for l in trange(num_runs):\n",
    "    dishab3['Deviant #4'] .append( ranch_sample(alpha_priors = full_alphas_1,exemplar_sequence = arr))\n",
    "\n",
    "    \n",
    "arr = ([exemplars[1].copy() for t in range(5) ] + [deviant_exemplar.copy() for t in range(1) ] + [exemplars[1].copy() for t in range(0) ] )\n",
    "print(arr)\n",
    "\n",
    "for l in trange(num_runs):\n",
    "    dishab3['Deviant #6'] .append(ranch_sample(alpha_priors = full_alphas_1,exemplar_sequence = arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264f84d",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42cc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers = 'ov^s'\n",
    "for i, key in enumerate(dishab3):\n",
    "    plt.plot([1,2,3,4,5,6],  [np.mean([x[i] for x in dishab3[key]])  for i in range(6)], marker = markers[i], label = key)\n",
    "    plt.legend(fontsize = 12)\n",
    "    \n",
    "plt.xlabel('Repetition', fontsize =13)\n",
    "plt.ylabel('Looking Iterations', fontsize=13)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd42cbc",
   "metadata": {},
   "source": [
    "## Statistical Significance Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac35c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for deviant in [2,4,6]:\n",
    "    col_name = f'Deviant #{deviant}' \n",
    "    arr_control = dishab3['Control']\n",
    "    arr_complex = dishab3[col_name]\n",
    "    z_value, p_value = z_score_p_val([x[deviant - 1] for x in arr_simple], [x[deviant - 1] for x in arr_complex])\n",
    "    \n",
    "    \n",
    "    print(f'{col_name} vs Control Z-score: ', z_value)\n",
    "    print(f'{col_name} vs Control p-value: ', p_value)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccad2ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
