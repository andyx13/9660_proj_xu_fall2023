{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064ec52d",
   "metadata": {},
   "source": [
    "# Multinomial RANCH Project Notebook\n",
    "\n",
    "#### Author: Guanpeng (Andy) Xu\n",
    "#### 9.660 Final Project, Fall 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455ae45",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efd6749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.special import gammaln as loggamma, digamma\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee892f6",
   "metadata": {},
   "source": [
    "## Exemplars and Priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073173ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplars =  np.array([[0,0,0], [0,0,1], [0,1,2], [1,2,3]]).astype(float) #feature values 0,1,2,3,4\n",
    "default_exemplars = np.array([np.array([0,0,1]).astype(float) for i in range(6)]).astype(float)\n",
    "\n",
    "deviant_exemplar = np.array([4,0,0]).astype(float)\n",
    "\n",
    "full_alphas_1 = np.array([[4, 1, 1, 1, 1],\n",
    "       [4, 1, 1, 1, 1],\n",
    "       [4, 1, 1, 1, 1]]).astype(float)\n",
    "full_alphas_2 = np.array([[3.6, 3.6, 3.6, 3.6, 3.6],\n",
    "       [3.6, 3.6, 3.6, 3.6, 3.6],\n",
    "       [3.6, 3.6, 3.6, 3.6, 3.6]]).astype(float) - 2.0\n",
    "\n",
    "full_alphas_3 = np.array([[0.04, 1.99, 1.99, 1.99, 1.99],\n",
    "       [0.04, 1.99, 1.99, 1.99, 1.99],\n",
    "       [0.04, 1.99, 1.99, 1.99, 1.99]]).astype(float)\n",
    "\n",
    "full_alphas_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a844901c",
   "metadata": {},
   "source": [
    "## RANCH implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e909e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_ = 0.065\n",
    "epsilons = [0.001, 0.01, 0.1, 0.2, 0.5, 0.7]\n",
    "epsilon_hat = 0.065\n",
    "EIG_env_ = 0.01\n",
    "numft, numval = full_alphas_1.shape\n",
    "\n",
    "\n",
    "def perturb(exemplar, epsilon = epsilon_hat):\n",
    "    rand_arr = np.random.rand(numft)\n",
    "    out = []\n",
    "    for ind in range(numft):\n",
    "        if rand_arr[ind] >= epsilon:\n",
    "            out.append(exemplar[ind])\n",
    "        else:\n",
    "            permute = 1 + int(4* rand_arr[ind]/epsilon) \n",
    "            out.append( (exemplar[ind] + permute)%5) \n",
    "        pass\n",
    "    return np.array(out)\n",
    "\n",
    "def compute_posterior_change(zs, epsilon):\n",
    "    \n",
    "    if len(zs) == 0:\n",
    "        return 1.0 * (np.ones((numval, ))/numval).astype(float)\n",
    "\n",
    "    \n",
    "    assert epsilon > 0\n",
    "    assert epsilon < 1\n",
    "    ci = np.ones((len(zs), numval)).astype(float) * np.log((epsilon/(numval - 1)))\n",
    "    \n",
    "    #each row is a z, each column is a feature value for y.\n",
    "    ci[[i for i in range(len(zs))], [int(x+ 0.001) for x in zs]] = np.log(1 - epsilon)\n",
    "    ci_out = np.sum(ci, axis = 0)\n",
    "    \n",
    "    assert ci_out.shape[0] == numval\n",
    "    return np.exp(ci_out)/np.sum(np.exp(ci_out))\n",
    "\n",
    "\n",
    "def EIG(alpha_priors, zs, epsilon = epsilon_):\n",
    "    \n",
    "    M = (1 - (numval * epsilon/(numval-1))) * np.eye(numval) + (epsilon/(numval - 1)) * np.ones((numval, numval))\n",
    "    \n",
    "    pi = compute_posterior_change(zs, epsilon)\n",
    "    \n",
    "    di = np.matmul(M, pi)\n",
    "    \n",
    "    probs = (di+alpha_priors)\n",
    "    probs = probs/np.sum(probs)\n",
    "    \n",
    "    EIG_ = 0\n",
    "    \n",
    "    for val in range(numval):\n",
    "        post_change = compute_posterior_change(zs + [val], epsilon)\n",
    "        EIG_ += KL(alpha_priors + post_change, alpha_priors + pi) * probs[val]\n",
    "\n",
    "    return EIG_\n",
    "\n",
    "\n",
    "def KL(alphas_1, alphas_2):\n",
    "    \n",
    "    loggamma1 = loggamma(np.sum(alphas_1))\n",
    "    loggamma2 = loggamma(np.sum(alphas_2))\n",
    "    loggamma3 = np.sum(loggamma(alphas_1))\n",
    "    loggamma4 = np.sum(loggamma(alphas_2))\n",
    "    diffs = alphas_1 - alphas_2\n",
    "    digamma_diffs = digamma(alphas_1) - digamma(np.sum(alphas_1))\n",
    "    \n",
    "    return (loggamma1 - loggamma2) + (loggamma4 - loggamma3) + np.dot(diffs, digamma_diffs)\n",
    "\n",
    "\n",
    "def ranch_sample(alpha_priors = full_alphas_1, exemplar_sequence = default_exemplars[:1], epsilon = epsilon_hat, EIG_env = EIG_env_):\n",
    "    \n",
    "    \"\"\"\n",
    "    Return a sequence of looking times for each exemplar in the sequence, given a set of input priors and epsilon.\n",
    "    \"\"\"\n",
    "    \n",
    "    priors_modify = alpha_priors.copy()[:,:].astype(float)\n",
    "    out_array = []\n",
    "    \n",
    "    observations_so_far = []\n",
    "    \n",
    "    for exemplar in exemplar_sequence:\n",
    "        \n",
    "        r = 0 \n",
    "        \n",
    "        observations_so_far.append([])\n",
    "        sample = True\n",
    "        \n",
    "        while (sample and r < 5000): \n",
    "            z = perturb(exemplar, epsilon)\n",
    "            \n",
    "            EIG_next = 0\n",
    "            \n",
    "            for ft in range(numft):\n",
    "                zs_ft = [z[ft] for z in observations_so_far[-1]]\n",
    "                alphas_ft = priors_modify[ft,:].copy()\n",
    "                EIG_next += EIG(alphas_ft, zs_ft, epsilon)\n",
    "                \n",
    "            if (EIG_env + EIG_next) * np.random.rand() > EIG_next:\n",
    "                sample = False\n",
    "            r += 1\n",
    "            if r == 2500:\n",
    "                print('2500 iters done. EIG: ', EIG_next)\n",
    "                \n",
    "            if r == 5000:\n",
    "                print('Fail ', EIG_next)\n",
    "                \n",
    "            observations_so_far[-1].append(z)\n",
    "            \n",
    "        out_array.append(r)\n",
    "        for ft in range(numft):\n",
    "            zs_ft = [z[ft] for z in observations_so_far[-1]]\n",
    "            priors_modify[ft] += compute_posterior_change(zs_ft, epsilon)\n",
    "    \n",
    "    return np.array(out_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afa6728",
   "metadata": {},
   "source": [
    "## Multinomial RANCH Properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1d3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict_e = {}\n",
    "seq_dict_EIG = {}\n",
    "seq_dict_alphas = {}\n",
    "\n",
    "for epsilon__ in epsilons:\n",
    "    print('EPS: ', epsilon__)\n",
    "    for l in trange(1000):\n",
    "        seq_dict_e[epsilon__] = seq_dict_e.get(epsilon__, 0) +  0.001 * ranch_sample(epsilon = epsilon__)\n",
    "    \n",
    "print('')\n",
    "print('') \n",
    "for EIG_env__ in [0.001, 0.01, 0.1]:\n",
    "    print('EIG_env: ', EIG_env__)\n",
    "    for l in trange(1000):\n",
    "        seq_dict_EIG[EIG_env__] =seq_dict_EIG.get(EIG_env__, 0) + 0.001 * ranch_sample(EIG_env = EIG_env__)\n",
    "print('')\n",
    "print('')  \n",
    "for i, alpha_arr in enumerate([full_alphas_1, full_alphas_2, full_alphas_3]):\n",
    "    print('ALPHA_ARR: ', alpha_arr[0])\n",
    "    for l in trange(1000):\n",
    "        seq_dict_alphas[i] = seq_dict_alphas.get(i, 0) + 0.001 * ranch_sample(alpha_priors = alpha_arr.copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1cf5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_dict_EIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48705fe3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "seq_dict_alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9b3dc8",
   "metadata": {},
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d98c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dict(dict_):\n",
    "    names = []\n",
    "    values = []\n",
    "    \n",
    "    for key in dict_:\n",
    "        names.append(str(key))\n",
    "        values.append(dict_[key][0])\n",
    "        \n",
    "    return names,values\n",
    "\n",
    "plt.bar(plot_dict(seq_dict_e)[0], plot_dict(seq_dict_e)[1])\n",
    "plt.xlabel('Modeled Noise $(\\epsilon)$' , fontsize = 13)\n",
    "plt.ylabel('Mean Iterations sampled', fontsize = 13)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(plot_dict(seq_dict_EIG)[0], plot_dict(seq_dict_EIG)[1])\n",
    "plt.xlabel('Modeled EIG(env)', fontsize = 13)\n",
    "plt.ylabel('Mean Iterations sampled', fontsize = 13)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()\n",
    "\n",
    "plt.bar(['Control-Biased Prior', 'Neutral Prior', 'Deviant-Biased Prior'], plot_dict(seq_dict_alphas)[1] )\n",
    "\n",
    "plt.ylim(3, 4)\n",
    "\n",
    "plt.ylabel('Mean Iterations sampled', fontsize = 13)\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319fe5dc",
   "metadata": {},
   "source": [
    "## Complexity/Habituation Analysis\n",
    "\n",
    "### WARNING:\n",
    "The below does not replicate outside of my scratch notebook and I do NOT know why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc8854a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compl = {}\n",
    "\n",
    "for i in range(4):\n",
    "    arr = np.array([exemplars[i].copy() for t in range(6) ])\n",
    "    print(arr)\n",
    "\n",
    "    for l in trange(200): \n",
    "        compl[str(arr[0] + 1)] = compl.get(str(arr[0] + 1), 0) + 0.005 * ranch_sample(exemplar_sequence = arr)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in compl:   \n",
    "    plt.plot([1,2,3,4,5,6], compl[key], label = key)\n",
    "    \n",
    "means = []\n",
    "\n",
    "for i in range(6):\n",
    "    means.append(0)\n",
    "    for key in compl:\n",
    "        means[-1] += 0.25 *compl[key][i]\n",
    "plt.plot([1,2,3,4,5,6], means, label = 'Mean', color = 'black', linewidth = 2)\n",
    "plt.legend()  \n",
    "plt.xlabel('Repetition', fontsize = 13)\n",
    "plt.ylabel('Looking Iterations', fontsize = 13)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e8d629",
   "metadata": {},
   "source": [
    "## Dishabituation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194dea66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dishab = {}\n",
    "\n",
    "\n",
    "\n",
    "arr = ([exemplars[1].copy() for t in range(6) ])\n",
    "print(arr)\n",
    "\n",
    "for l in trange(1000):\n",
    "    dishab['Control'] = dishab.get('Control', 0) + 0.001 * ranch_sample(alpha_priors = full_alphas_1, exemplar_sequence = arr)\n",
    "\n",
    "arr = ([exemplars[1].copy() for t in range(1) ] + [deviant_exemplar.copy() for t in range(1) ] + [exemplars[1].copy() for t in range(4) ] )\n",
    "print(arr)\n",
    "\n",
    "for l in trange(1000):\n",
    "    dishab['Deviant #2'] = dishab.get('Deviant #2', 0) + 0.001 * ranch_sample(alpha_priors = full_alphas_1,exemplar_sequence = arr)\n",
    "\n",
    "\n",
    "arr = ([exemplars[1].copy() for t in range(3) ] + [deviant_exemplar.copy() for t in range(1) ] + [exemplars[1].copy() for t in range(2) ] )\n",
    "print(arr)\n",
    "\n",
    "for l in trange(1000):\n",
    "    dishab['Deviant #4'] = dishab.get('Deviant #4', 0) + 0.001 * ranch_sample(alpha_priors = full_alphas_1,exemplar_sequence = arr)\n",
    "\n",
    "    \n",
    "arr = ([exemplars[1].copy() for t in range(5) ] + [deviant_exemplar.copy() for t in range(1) ] + [exemplars[1].copy() for t in range(0) ] )\n",
    "print(arr)\n",
    "\n",
    "for l in trange(1000):\n",
    "    dishab['Deviant #6'] = dishab.get('Deviant #6', 0) + 0.001 * ranch_sample(alpha_priors = full_alphas_1,exemplar_sequence = arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21bbf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dishab:\n",
    "    plt.plot([1,2,3,4,5,6],  dishab[key], label = key)\n",
    "    plt.legend(fontsize = 12)\n",
    "    \n",
    "plt.xlabel('Repetition', fontsize = 13)\n",
    "plt.ylabel('Looking Iterations', fontsize = 13)\n",
    "\n",
    "plt.xticks(fontsize = 12)\n",
    "plt.yticks(fontsize = 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9450b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
